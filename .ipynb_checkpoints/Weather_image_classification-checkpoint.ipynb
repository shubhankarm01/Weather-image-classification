{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Uncomment below cell to use GPU for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_device = tf.config.experimental.list_physical_devices('GPU')\n",
    "print('No. of GPU: ', len(physical_device))\n",
    "tf.config.experimental.set_memory_growth(physical_device[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style = 'background: Red'> CNN for image classifiaction </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_folder =  'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Viewing some random images from the training folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = np.random.choice(os.listdir(train_folder), 6)\n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize=(15, 7),\n",
    "                         subplot_kw={'xticks': [], 'yticks': []})\n",
    "    \n",
    "axes = axes.flat\n",
    "\n",
    "for file, ax in list(zip(files, axes)) :\n",
    "    img_path = os.path.join(train_folder, file)\n",
    "    img = mpimg.imread(img_path)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading images and labels from the training folder and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_targets = pd.read_csv('Training_set.csv')\n",
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_targets[df_targets['filename'] == 'Image_1.jpg']['label'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_data = []\n",
    "image_label = []\n",
    "\n",
    "for dirc in os.listdir(train_folder):\n",
    "    file = os.path.join(train_folder, dirc)\n",
    "    image = cv2.imread(file, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (250, 250), interpolation = cv2.INTER_AREA)\n",
    "    image = np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image = image/255\n",
    "    image_data.append(image)\n",
    "    \n",
    "    label = df_targets[df_targets['filename'] == dirc]['label'].values[0]\n",
    "    image_label.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Augmenting some random images to increase training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"augmented_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating directory to save augmented images\n",
    "\n",
    "os.mkdir('augmented_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Creating 400 augmented images from 100 randomly choosen images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dirc in np.random.choice(os.listdir(train_folder), size = 200, replace = False):\n",
    "    file = os.path.join(train_folder, dirc)\n",
    "    image = cv2.imread(file, cv2.COLOR_BGR2RGB)\n",
    "    # image = cv2.resize(image, (250, 250), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    label = df_targets[df_targets['filename'] == dirc]['label'].values[0]\n",
    "    \n",
    "    # Increase rank of the image by adding an axis to make it compatible for ImageDataGenerator\n",
    "    # print(image.shape)\n",
    "    image = image.reshape((1,) + image.shape)\n",
    "    # print(image.shape)\n",
    "    \n",
    "    datagen = ImageDataGenerator(rotation_range = 20,\n",
    "                                 width_shift_range = 0.1,\n",
    "                                 height_shift_range = 0.1,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 horizontal_flip = True,\n",
    "                                 vertical_flip = True,\n",
    "                                 fill_mode = 'nearest')\n",
    "\n",
    "    i = 0\n",
    "    for batch in datagen.flow(image, save_to_dir = './augmented_images', save_prefix = label, save_format = 'jpg'):\n",
    "        i = i+1\n",
    "        if i>1:                  # Two augmentation for each image \n",
    "            break                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating zip file of augmented images folder\n",
    "\n",
    "# shutil.make_archive('augmented_images', 'zip', '/kaggle/working/augmented_images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding augmented images and corresponding labels to image_data and image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aug_images_folder = './augmented_images'\n",
    "\n",
    "for dirc in os.listdir(aug_images_folder):\n",
    "    file = os.path.join(aug_images_folder, dirc)\n",
    "    image = cv2.imread(file, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (250, 250), interpolation = cv2.INTER_AREA)\n",
    "    image = np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image = image/255\n",
    "    image_data.append(image)\n",
    "    \n",
    "    label = dirc.split('_')[0]\n",
    "    image_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(image_data), len(image_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Converting the object labels to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_targets = {v : k for k,v in enumerate(np.unique(image_label))}\n",
    "dict_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dict_targets['cloudy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = [dict_targets[image_label[i]] for i in range(len(image_label))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Construct the CNN neural network for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = tf.utils.to_categorical(targets, 5)\n",
    "\n",
    "# or use\n",
    "# np.array(list(map(int, targets)), np.float32),       \n",
    "# for sparse_categorical_crossentropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.models.Sequential()\n",
    "\n",
    "model.add(tf.layers.Conv2D(filters = 25, kernel_size = (3,3), strides = (2,2), activation = 'relu', input_shape = (250, 250, 3), padding = 'same')),\n",
    "# model.add(tf.layers.BatchNormalization())\n",
    "model.add(tf.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2))),\n",
    "\n",
    "model.add(tf.layers.Conv2D(filters = 45, kernel_size = (3,3), strides = (2,2), activation = 'relu', padding = 'same')),\n",
    "# model.add(tf.layers.BatchNormalization())\n",
    "model.add(tf.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2))),\n",
    "\n",
    "model.add(tf.layers.Flatten()),\n",
    "\n",
    "model.add(tf.layers.Dense(512, activation = 'tanh')),\n",
    "model.add(tf.layers.Dropout(rate = 0.2)),\n",
    "model.add(tf.layers.Dense(128, activation = 'tanh')),\n",
    "model.add(tf.layers.Dropout(rate = 0.1)),\n",
    "\n",
    "model.add(tf.layers.Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x = np.array(image_data, np.float32),\n",
    "          y = targets,\n",
    "          epochs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_set = pd.read_csv('Testing_set.csv')\n",
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename =  testing_set['filename'].values.tolist()\n",
    "filename[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_folder =  'test'\n",
    "\n",
    "test_image_data = []\n",
    "# test_image_label = []\n",
    "\n",
    "for dirc in filename:\n",
    "    file = os.path.join(test_folder, dirc)\n",
    "    image = cv2.imread(file, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (250, 250), interpolation = cv2.INTER_AREA)\n",
    "    image = np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image = image/255\n",
    "    test_image_data.append(image)\n",
    "    \n",
    "#     label = df_test_targets[df_test_targets['filename'] == dirc]['label'].values[0]\n",
    "#     test_image_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model.predict(np.array(test_image_data, np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_pred = []\n",
    "\n",
    "for i in pred:\n",
    "    list_pred.append(np.argmax(i))\n",
    "    \n",
    "list_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting predicted numerical labels back to string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for i in list_pred:\n",
    "    [prediction.append(k) for k,v in dict_targets.items() if v == i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(test_image_data), len(list_pred), len(prediction)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_results = pd.DataFrame(prediction, index = filename)\n",
    "prediction_results.columns = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_results.to_csv('CNN_prediction_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style = 'background: Red'> Pre-trained model - Huggingface </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_targets = pd.read_csv('Training_set.csv')\n",
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image \n",
    "\n",
    "train_folder =  'train'\n",
    "\n",
    "image_data = []\n",
    "image_label = []\n",
    "\n",
    "for dirc in os.listdir(train_folder):\n",
    "    file = os.path.join(train_folder, dirc)\n",
    "    \n",
    "    img = image.load_img(file, target_size=(100, 100))\n",
    "    img = image.img_to_array(img)\n",
    "    # img = np.expand_dims(img, axis=0)\n",
    "    image_data.append(img)\n",
    "    \n",
    "    label = df_targets[df_targets['filename'] == dirc]['label'].values[0]\n",
    "    image_label.append(label)\n",
    "    \n",
    "# image_data = np.vstack(image_data)\n",
    "\n",
    "# image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(image_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating dictionary of labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_labels = {v : k for k,v in enumerate(np.unique(image_label))}\n",
    "dict_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Converting labels from string to numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_label = [dict_labels[image_label[i]] for i in range(len(image_label))]\n",
    "image_label[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Splitting image_data and image_label into train and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = len(image_data)\n",
    "split = int(0.80*n)\n",
    "\n",
    "train_image_dict = {'images': image_data[:split], 'labels':image_label[:split]}\n",
    "val_image_dict = {'images': image_data[split:], 'labels':image_label[split:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Converting data dictionary into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds_train = Dataset.from_dict(train_image_dict)\n",
    "ds_val = Dataset.from_dict(val_image_dict)\n",
    "\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <span style = 'background: Yellow'> tensorflow implimentation of Hugging face model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel, AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing input dataset \n",
    "\n",
    "'google/vit-base-patch16-224' takes input data as pixel_values of size (color, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained('google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_images(example_batch):\n",
    "    \n",
    "    images = example_batch['images']\n",
    "\n",
    "    images = [np.array(image, dtype=np.uint8) for image in images]\n",
    "    \n",
    "    # convert to list of NumPy arrays of shape (C, H, W)\n",
    "    images = [np.moveaxis(image, source=-1, destination=0) for image in images]\n",
    "    \n",
    "    # preprocess and add pixel_values\n",
    "    inputs = feature_extractor(images=images)\n",
    "    \n",
    "    example_batch['pixel_values'] = inputs['pixel_values']\n",
    "\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list = list(dict_labels.keys())\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to define the features ourselves as both the img and pixel_values have a 3D shape \n",
    "\n",
    "from datasets import Features, ClassLabel, Array3D\n",
    "\n",
    "features = Features({'images': Array3D(dtype=\"int64\", shape=(100, 100, 3)),\n",
    "                     'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "                     'labels': ClassLabel(names = label_list),\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adding pixel_values feature in ds_train and ds_val by using defined preprocess_images() function for huggingface model \n",
    "\n",
    "preprocessed_ds_train = ds_train.map(preprocess_images, batched = True, features = features)\n",
    "preprocessed_ds_val = ds_val.map(preprocess_images, batched = True, features = features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert preprocessed datasets into tensorflow datasets and collate to make batches of inpute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "collator = DefaultDataCollator(return_tensors = 'tf')\n",
    "\n",
    "tf_train_dataset = preprocessed_ds_train.to_tf_dataset(columns = ['pixel_values'],\n",
    "                                                       label_cols = ['labels'],\n",
    "                                                       shuffle = True,\n",
    "                                                       batch_size = 20,\n",
    "                                                       collate_fn = collator)\n",
    "\n",
    "tf_val_dataset = preprocessed_ds_val.to_tf_dataset(columns = ['pixel_values'],\n",
    "                                                   label_cols = ['labels'],\n",
    "                                                   shuffle = True,\n",
    "                                                   batch_size = 20,\n",
    "                                                   collate_fn = collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Constructing model with pre-trained model as the non-trainable part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TFAutoModel.from_pretrained('google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as tf\n",
    "\n",
    "input_layer = tf.layers.Input(shape=(3, 224, 224), \n",
    "                              name='pixel_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_hidden_state = model(input_layer).last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = tf.layers.Dense(5, activation = 'softmax')(last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(tf.optimizers.Adam(lr = 5e-3), \n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(tf_train_dataset,\n",
    "         validation_data = tf_val_dataset,\n",
    "         epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Classification on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_set = pd.read_csv('Testing_set.csv')\n",
    "\n",
    "filename =  testing_set['filename'].values.tolist()\n",
    "\n",
    "Testing_folder =  'test'\n",
    "\n",
    "file_path = [Testing_folder + '/' +file for file in filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image \n",
    "\n",
    "pred_image_data = []\n",
    "\n",
    "for file in file_path:\n",
    "    img = image.load_img(file, target_size=(100, 100))\n",
    "    img = image.img_to_array(img)\n",
    "    # img = np.expand_dims(img, axis=0)\n",
    "    pred_image_data.append(img)\n",
    "    \n",
    "# pred_image_data = np.vstack(pred_image_data)\n",
    "    \n",
    "pred_image_dict = {'images': pred_image_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_pred = Dataset.from_dict(pred_image_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_ds_pred = ds_pred.map(preprocess_images, batched = True, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_ds_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "collator = DefaultDataCollator(return_tensors = 'tf')\n",
    "\n",
    "tf_pred_dataset = preprocessed_ds_pred.to_tf_dataset(columns = ['pixel_values'],\n",
    "                                                       shuffle = True,\n",
    "                                                       batch_size = 20,\n",
    "                                                       collate_fn = collator\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_pred_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(tf_pred_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = dict_labels\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "predictions.columns = ['label']\n",
    "\n",
    "predictions.to_csv('tensorflow_prediction_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <span style = 'background: Yellow'> pytorch implimentation of Hugging face model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing input dataset \n",
    "\n",
    "'google/vit-base-patch16-224' takes input data as pixel_values of size (color, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained('google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_images(example_batch):\n",
    "    \n",
    "    images = example_batch['images']\n",
    "    \n",
    "    images = [np.array(image, dtype=np.uint8) for image in images]\n",
    "    \n",
    "    # convert to list of NumPy arrays of shape (C, H, W)\n",
    "    images = [np.moveaxis(image, source=-1, destination=0) for image in images]\n",
    "    \n",
    "    # preprocess and add pixel_values\n",
    "    inputs = feature_extractor(images=images)\n",
    "    example_batch['pixel_values'] = inputs['pixel_values']\n",
    "\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list = list(dict_labels.keys())\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to define the features ourselves as both the img and pixel_values have a 3D shape\n",
    "\n",
    "from datasets import Features, ClassLabel, Array3D\n",
    " \n",
    "features = Features({'images': Array3D(dtype=\"int64\", shape=(100, 100, 3)),\n",
    "                     'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "                     'labels': ClassLabel(names = label_list)\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_ds_train = ds_train.map(preprocess_images, batched = True, batch_size = 20, features = features)\n",
    "preprocessed_ds_val = ds_val.map(preprocess_images, batched = True, batch_size = 20, features = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_ds_train.info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_ds_train.features['labels'].names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Constructing model with pre-trained model as the non-trainable part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch.nn as nn\n",
    "\n",
    "class ViTForImageClassification(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ViTForImageClassification, self).__init__()\n",
    "        self.model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        \n",
    "        # Freezing layers of ViTModel\n",
    "        for lay in self.model.parameters():\n",
    "            lay.requires_grad = False\n",
    "    \n",
    "        self.linear = nn.Linear(self.model.config.hidden_size, 5)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, pixel_values, labels = None):\n",
    "        outputs = self.model(pixel_values = pixel_values)\n",
    "        output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.linear(output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_function = nn.CrossEntropyLoss()\n",
    "            loss = loss_function(logits, labels)\n",
    "        \n",
    "        return SequenceClassifierOutput(loss = loss, logits = logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(output_dir = \"./pytorch_results\",\n",
    "                         evaluation_strategy = \"epoch\",\n",
    "                         learning_rate = 5e-3,\n",
    "                         num_train_epochs = 1,\n",
    "                         per_device_train_batch_size = 20,\n",
    "                         per_device_eval_batch_size = 20,\n",
    "                         gradient_accumulation_steps = 1,\n",
    "                        )\n",
    "\n",
    "# args = TrainingArguments(output_dir = \"./pytorch_results\",\n",
    "#                          optim = 'adamw_torch',\n",
    "#                          evaluation_strategy = \"steps\",\n",
    "#                          save_strategy = \"steps\",\n",
    "#                          save_steps = 10,\n",
    "#                          eval_steps = 10,\n",
    "#                          learning_rate = 5e-3,\n",
    "#                          num_train_epochs = 1,\n",
    "#                          per_device_train_batch_size = 20,\n",
    "#                          per_device_eval_batch_size = 20,\n",
    "#                          gradient_accumulation_steps = 1,\n",
    "#                          weight_decay = 0.01,\n",
    "#                          load_best_model_at_end=True,\n",
    "#                          metric_for_best_model = metric_name,\n",
    "#                          logging_dir = './pytorch_results/logs',\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ViTForImageClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trainable parameters in model\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions = predictions, references = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model,\n",
    "                  args,\n",
    "                  train_dataset = preprocessed_ds_train,\n",
    "                  eval_dataset = preprocessed_ds_val,\n",
    "                  data_collator = data_collator,\n",
    "                  compute_metrics = compute_metrics\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_set = pd.read_csv('Testing_set.csv')\n",
    "\n",
    "filename =  testing_set['filename'].values.tolist()\n",
    "\n",
    "Testing_folder =  'test'\n",
    "\n",
    "file_path = [Testing_folder + '/' +file for file in filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image \n",
    "\n",
    "pred_image_data = []\n",
    "\n",
    "for file in file_path:\n",
    "    img = image.load_img(file, target_size=(100, 100))\n",
    "    img = image.img_to_array(img)\n",
    "    # img = np.expand_dims(img, axis=0)\n",
    "    pred_image_data.append(img)\n",
    "    \n",
    "# pred_image_data = np.vstack(pred_image_data)\n",
    "    \n",
    "pred_image_dict = {'images': pred_image_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred = Dataset.from_dict(pred_image_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_ds_pred = ds_pred.map(preprocess_images, batched = True, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_ds_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = trainer.predict(preprocessed_ds_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = [np.argmax(x) for x in outputs.predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = dict_labels\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "predictions.columns = ['label']\n",
    "\n",
    "predictions.to_csv('pytorch_prediction_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# <span style = 'background: Red'> Pre-trained models - from tf.keras.application </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Loading images path and label into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_targets = pd.read_csv('Training_set.csv')\n",
    "\n",
    "import os\n",
    "\n",
    "train_folder =  'train'\n",
    "file_path = []\n",
    "labels = []\n",
    "\n",
    "for dirc in os.listdir(train_folder):\n",
    "    file = os.path.join(train_folder, dirc)\n",
    "    file_path.append(file)\n",
    "    \n",
    "    label = df_targets[df_targets['filename'] == dirc]['label'].values[0]\n",
    "    labels.append(label)\n",
    "    \n",
    "image_data = pd.DataFrame({'file_path': file_path, 'labels': labels})\n",
    "\n",
    "image_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(image_data, test_size = 0.2, random_state = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Generating and preprocessing input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "VGG16_preprocess = preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = VGG16_preprocess)\\\n",
    "                                   .flow_from_dataframe(dataframe = train_df, \n",
    "                                                        x_col = 'file_path', \n",
    "                                                        y_col = 'labels', \n",
    "                                                        target_size = (224, 224), \n",
    "                                                        batch_size = 20, \n",
    "                                                        seed = 6\n",
    "                                                        )\n",
    "val_datagen = ImageDataGenerator(preprocessing_function = VGG16_preprocess)\\\n",
    "                                   .flow_from_dataframe(dataframe = val_df, \n",
    "                                                        x_col = 'file_path', \n",
    "                                                        y_col = 'labels', \n",
    "                                                        target_size = (224, 224), \n",
    "                                                        batch_size = 20, \n",
    "                                                        seed = 6,\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 20, figsize = (20, 20))\n",
    "\n",
    "for img, ax in zip(imgs, axes):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# def image_generation(pre, train):\n",
    "#     train_datagen = ImageDataGenerator(preprocessing_function = pre, validation_split = 0.15)\n",
    "    \n",
    "#     train_gen = train_datagen.flow_from_dataframe(\n",
    "#                                                     dataframe=train,\n",
    "#                                                     x_col='file_path',\n",
    "#                                                     y_col='labels',\n",
    "#                                                     target_size=(100,100),\n",
    "#                                                     class_mode='categorical',\n",
    "#                                                     batch_size=32,\n",
    "#                                                     shuffle=True,\n",
    "#                                                     seed=0,\n",
    "        \n",
    "#                                                     subset='training',\n",
    "        \n",
    "#                                                     rotation_range=30,\n",
    "#                                                     zoom_range=0.15,\n",
    "#                                                     width_shift_range=0.2,\n",
    "#                                                     height_shift_range=0.2,\n",
    "#                                                     shear_range=0.15,\n",
    "#                                                     horizontal_flip=True,\n",
    "#                                                     fill_mode=\"nearest\"\n",
    "#                                                 ) \n",
    "    \n",
    "#     valid_gen = train_datagen.flow_from_dataframe(\n",
    "#                                                     dataframe=train,\n",
    "#                                                     x_col='file_path',\n",
    "#                                                     y_col='labels',\n",
    "#                                                     target_size=(100,100),\n",
    "#                                                     class_mode='categorical',\n",
    "#                                                     batch_size=32,\n",
    "#                                                     shuffle=False,\n",
    "#                                                     seed=0,\n",
    "        \n",
    "#                                                     subset='validation',\n",
    "        \n",
    "#                                                     rotation_range=30,\n",
    "#                                                     zoom_range=0.15,\n",
    "#                                                     width_shift_range=0.2,\n",
    "#                                                     height_shift_range=0.2,\n",
    "#                                                     shear_range=0.15,\n",
    "#                                                     horizontal_flip=True,\n",
    "#                                                     fill_mode=\"nearest\"\n",
    "#                                                 )\n",
    "    \n",
    "#     return train_gen, valid_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Constructing model with pre-trained model as the non-trainable part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg16 = VGG16(include_top = False, pooling = 'avg', input_shape = (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg16.trainable = False\n",
    "\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(vgg16)\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# callbacks  = [EarlyStopping(monitor = 'val_loss',\n",
    "#                             min_delta = 0,\n",
    "#                             patience = 2,\n",
    "#                             mode = 'auto'\n",
    "#                             )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x = train_datagen,\n",
    "          validation_data = val_datagen, \n",
    "          epochs = 1, \n",
    "          # steps_per_epoch = 42, \n",
    "          # callbacks = callbacks,\n",
    "          verbose = 2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import VGG19\n",
    "# from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "# VGG19_preprocess = preprocess_input\n",
    "\n",
    "# train_gen_VGG19, valid_gen_VGG19 = image_generation(VGG19_preprocess, train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Classification on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T07:56:20.431935Z",
     "iopub.status.busy": "2022-06-19T07:56:20.431555Z",
     "iopub.status.idle": "2022-06-19T07:56:20.444094Z",
     "shell.execute_reply": "2022-06-19T07:56:20.443225Z",
     "shell.execute_reply.started": "2022-06-19T07:56:20.43188Z"
    }
   },
   "outputs": [],
   "source": [
    "testing_set = pd.read_csv('Testing_set.csv')\n",
    "\n",
    "filename =  testing_set['filename'].values.tolist()\n",
    "\n",
    "Testing_folder =  'test'\n",
    "file_path = []\n",
    "\n",
    "for dirc in filename:\n",
    "    file = os.path.join(Testing_folder, dirc)\n",
    "    file_path.append(file)\n",
    "    \n",
    "pred_image_data = pd.DataFrame({'file_path': file_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T07:56:35.130877Z",
     "iopub.status.busy": "2022-06-19T07:56:35.130512Z",
     "iopub.status.idle": "2022-06-19T07:56:35.135414Z",
     "shell.execute_reply": "2022-06-19T07:56:35.134444Z",
     "shell.execute_reply.started": "2022-06-19T07:56:35.130845Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_datagen = ImageDataGenerator(preprocessing_function = VGG16_preprocess)\\\n",
    "                                   .flow_from_dataframe(dataframe = pred_image_data, \n",
    "                                                        x_col = 'file_path',  \n",
    "                                                        class_mode = None,\n",
    "                                                        target_size = (224, 224), \n",
    "                                                        batch_size = 20, \n",
    "                                                        seed = 6\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T07:56:38.946592Z",
     "iopub.status.busy": "2022-06-19T07:56:38.94623Z",
     "iopub.status.idle": "2022-06-19T07:56:42.589775Z",
     "shell.execute_reply": "2022-06-19T07:56:42.589054Z",
     "shell.execute_reply.started": "2022-06-19T07:56:38.946561Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "predictions = model.predict(pred_datagen)\n",
    "predictions = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T07:56:42.591647Z",
     "iopub.status.busy": "2022-06-19T07:56:42.591292Z",
     "iopub.status.idle": "2022-06-19T07:56:42.624607Z",
     "shell.execute_reply": "2022-06-19T07:56:42.623787Z",
     "shell.execute_reply.started": "2022-06-19T07:56:42.591612Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T07:56:42.626468Z",
     "iopub.status.busy": "2022-06-19T07:56:42.625721Z",
     "iopub.status.idle": "2022-06-19T07:56:43.181802Z",
     "shell.execute_reply": "2022-06-19T07:56:43.180948Z",
     "shell.execute_reply.started": "2022-06-19T07:56:42.626428Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = (train_datagen.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T07:56:42.626468Z",
     "iopub.status.busy": "2022-06-19T07:56:42.625721Z",
     "iopub.status.idle": "2022-06-19T07:56:43.181802Z",
     "shell.execute_reply": "2022-06-19T07:56:43.180948Z",
     "shell.execute_reply.started": "2022-06-19T07:56:42.626428Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T07:56:46.059361Z",
     "iopub.status.busy": "2022-06-19T07:56:46.058634Z",
     "iopub.status.idle": "2022-06-19T07:56:46.066508Z",
     "shell.execute_reply": "2022-06-19T07:56:46.065553Z",
     "shell.execute_reply.started": "2022-06-19T07:56:46.059322Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "predictions.columns = ['label']\n",
    "\n",
    "predictions.to_csv('tf_keras_api_prediction_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T07:52:48.320868Z",
     "iopub.status.busy": "2022-06-19T07:52:48.32051Z",
     "iopub.status.idle": "2022-06-19T07:52:48.33194Z",
     "shell.execute_reply": "2022-06-19T07:52:48.329312Z",
     "shell.execute_reply.started": "2022-06-19T07:52:48.320836Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "predictions.columns = ['label']\n",
    "\n",
    "predictions.to_csv('prediction_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
